{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def set_axis_style(ax, labels):\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels)\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_location = '../results/toxic_measures/'\n",
    "\n",
    "original = json.load(open(f'{folder_location}original.json'))\n",
    "\n",
    "opt_first_line = json.load(open(f'{folder_location}opt_first_line.json'))\n",
    "opt_256_tokens = json.load(open(f'{folder_location}opt_256_tokens.json'))\n",
    "opt_512_tokens = json.load(open(f'{folder_location}opt_512_tokens.json'))\n",
    "\n",
    "llama_first_line = json.load(open(f'{folder_location}llama_first_line.json'))\n",
    "llama_256_tokens = json.load(open(f'{folder_location}llama_256_tokens.json'))\n",
    "llama_512_tokens = json.load(open(f'{folder_location}llama_512_tokens.json'))\n",
    "\n",
    "alpaca_1 = json.load(open(f'{folder_location}alpaca_1.json'))\n",
    "alpaca_3 = json.load(open(f'{folder_location}alpaca_3.json'))\n",
    "\n",
    "alpaca_free_2 = json.load(open(f'{folder_location}alpaca_free_2.json'))\n",
    "alpaca_free_4 = json.load(open(f'{folder_location}alpaca_free_4.json'))\n",
    "\n",
    "def convert_to_single(dic):\n",
    "    vals = {\n",
    "        'toxic': [],\n",
    "        'severe_toxic': [],\n",
    "        'obscene': [],\n",
    "        'threat': [],\n",
    "        'insult': [],\n",
    "        'identity_hate': [],\n",
    "    }\n",
    "    \n",
    "    for e1 in dic:\n",
    "        for e2 in e1:\n",
    "            vals[e2['label']].append(e2['score'])\n",
    "    return vals\n",
    "\n",
    "original = convert_to_single(original)\n",
    "\n",
    "opt_first_line = convert_to_single(opt_first_line)\n",
    "opt_256_tokens = convert_to_single(opt_256_tokens)\n",
    "opt_512_tokens = convert_to_single(opt_512_tokens)\n",
    "\n",
    "llama_first_line = convert_to_single(llama_first_line)\n",
    "llama_256_tokens = convert_to_single(llama_256_tokens)\n",
    "llama_512_tokens = convert_to_single(llama_512_tokens)\n",
    "\n",
    "alpaca_1 = convert_to_single(alpaca_1)\n",
    "alpaca_3 = convert_to_single(alpaca_3)\n",
    "\n",
    "alpaca_free_2 = convert_to_single(alpaca_free_2)\n",
    "alpaca_free_4 = convert_to_single(alpaca_free_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "....\n",
      "Real Stories: [1047   46   17   16   12    8    6   11    9    2]\n",
      "OPT-Line: [987  26  15   7   6   4  10   4   9   3]\n",
      "OPT-256: [1075   27   22    8    8    9    3    2    7    6]\n",
      "OPT-512: [1126   32   24   14   12    5    1   11    7   10]\n",
      "LLaMA-Line: [987  26  15   7   6   4  10   4   9   3]\n",
      "LLaMA-256: [1075   27   22    8    8    9    3    2    7    6]\n",
      "LLaMA-512: [1126   32   24   14   12    5    1   11    7   10]\n",
      "Alpaca: T1: [987  26  15   7   6   4  10   4   9   3]\n",
      "Alpaca: T2: [987  26  15   7   6   4  10   4   9   3]\n",
      "Alpaca: T3: [987  26  15   7   6   4  10   4   9   3]\n",
      "Alpaca: T4: [987  26  15   7   6   4  10   4   9   3]\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "def get_toxic_measure(label='toxic'):\n",
    "    print(label)\n",
    "    print('....')\n",
    "    bin_labels = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "    # original\n",
    "    counts, _ = np.histogram(original[label], bins=bin_labels)\n",
    "    print(f'Real Stories: {counts}')\n",
    "\n",
    "    counts, _ = np.histogram(opt_first_line[label], bins=bin_labels)\n",
    "    print(f'OPT-Line: {counts}')\n",
    "    counts, _ = np.histogram(opt_256_tokens[label], bins=bin_labels)\n",
    "    print(f'OPT-256: {counts}')\n",
    "    counts, _ = np.histogram(opt_512_tokens[label], bins=bin_labels)\n",
    "    print(f'OPT-512: {counts}')\n",
    "\n",
    "    counts, _ = np.histogram(llama_first_line[label], bins=bin_labels)\n",
    "    print(f'LLaMA-Line: {counts}')\n",
    "    counts, _ = np.histogram(llama_256_tokens[label], bins=bin_labels)\n",
    "    print(f'LLaMA-256: {counts}')\n",
    "    counts, _ = np.histogram(llama_512_tokens[label], bins=bin_labels)\n",
    "    print(f'LLaMA-512: {counts}')\n",
    "\n",
    "    counts, _ = np.histogram(alpaca_1[label], bins=bin_labels)\n",
    "    print(f'Alpaca: T1: {counts}')\n",
    "    counts, _ = np.histogram(alpaca_free_2[label], bins=bin_labels)\n",
    "    print(f'Alpaca: T2: {counts}')\n",
    "    counts, _ = np.histogram(alpaca_3[label], bins=bin_labels)\n",
    "    print(f'Alpaca: T3: {counts}')\n",
    "    counts, _ = np.histogram(alpaca_free_4[label], bins=bin_labels)\n",
    "    print(f'Alpaca: T4: {counts}')\n",
    "    print('##############')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "....\n",
      "Real Stories: [1047   46   17   16   12    8    6   11    9    2]\n",
      "OPT-Line: [987  26  15   7   6   4  10   4   9   3]\n",
      "OPT-256: [1075   27   22    8    8    9    3    2    7    6]\n",
      "OPT-512: [1126   32   24   14   12    5    1   11    7   10]\n",
      "LLaMA-Line: [987  26  15   7   6   4  10   4   9   3]\n",
      "LLaMA-256: [1075   27   22    8    8    9    3    2    7    6]\n",
      "LLaMA-512: [1126   32   24   14   12    5    1   11    7   10]\n",
      "Alpaca: T1: [987  26  15   7   6   4  10   4   9   3]\n",
      "Alpaca: T2: [987  26  15   7   6   4  10   4   9   3]\n",
      "Alpaca: T3: [987  26  15   7   6   4  10   4   9   3]\n",
      "Alpaca: T4: [987  26  15   7   6   4  10   4   9   3]\n",
      "##############\n",
      "severe_toxic\n",
      "....\n",
      "Real Stories: [1174    0    0    0    0    0    0    0    0    0]\n",
      "OPT-Line: [1071    0    0    0    0    0    0    0    0    0]\n",
      "OPT-256: [1166    0    1    0    0    0    0    0    0    0]\n",
      "OPT-512: [1242    0    0    0    0    0    0    0    0    0]\n",
      "LLaMA-Line: [1071    0    0    0    0    0    0    0    0    0]\n",
      "LLaMA-256: [1166    0    1    0    0    0    0    0    0    0]\n",
      "LLaMA-512: [1242    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T1: [1071    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T2: [1071    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T3: [1071    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T4: [1071    0    0    0    0    0    0    0    0    0]\n",
      "##############\n",
      "obscene\n",
      "....\n",
      "Real Stories: [1170    0    2    1    0    1    0    0    0    0]\n",
      "OPT-Line: [1062    3    0    1    1    0    1    1    1    1]\n",
      "OPT-256: [1164    0    0    0    0    1    1    0    0    1]\n",
      "OPT-512: [1237    0    5    0    0    0    0    0    0    0]\n",
      "LLaMA-Line: [1062    3    0    1    1    0    1    1    1    1]\n",
      "LLaMA-256: [1164    0    0    0    0    1    1    0    0    1]\n",
      "LLaMA-512: [1237    0    5    0    0    0    0    0    0    0]\n",
      "Alpaca: T1: [1062    3    0    1    1    0    1    1    1    1]\n",
      "Alpaca: T2: [1062    3    0    1    1    0    1    1    1    1]\n",
      "Alpaca: T3: [1062    3    0    1    1    0    1    1    1    1]\n",
      "Alpaca: T4: [1062    3    0    1    1    0    1    1    1    1]\n",
      "##############\n",
      "threat\n",
      "....\n",
      "Real Stories: [1159    3    1    2    2    4    2    1    0    0]\n",
      "OPT-Line: [1061    2    1    1    0    2    2    1    1    0]\n",
      "OPT-256: [1154    3    0    2    1    5    1    0    1    0]\n",
      "OPT-512: [1217    0    4   10    1    6    0    4    0    0]\n",
      "LLaMA-Line: [1061    2    1    1    0    2    2    1    1    0]\n",
      "LLaMA-256: [1154    3    0    2    1    5    1    0    1    0]\n",
      "LLaMA-512: [1217    0    4   10    1    6    0    4    0    0]\n",
      "Alpaca: T1: [1061    2    1    1    0    2    2    1    1    0]\n",
      "Alpaca: T2: [1061    2    1    1    0    2    2    1    1    0]\n",
      "Alpaca: T3: [1061    2    1    1    0    2    2    1    1    0]\n",
      "Alpaca: T4: [1061    2    1    1    0    2    2    1    1    0]\n",
      "##############\n",
      "insult\n",
      "....\n",
      "Real Stories: [1151    6    1    4    6    3    3    0    0    0]\n",
      "OPT-Line: [1048    7    4    6    4    0    1    1    0    0]\n",
      "OPT-256: [1147    4    3    7    0    5    1    0    0    0]\n",
      "OPT-512: [1213    7    1    5    6    5    5    0    0    0]\n",
      "LLaMA-Line: [1048    7    4    6    4    0    1    1    0    0]\n",
      "LLaMA-256: [1147    4    3    7    0    5    1    0    0    0]\n",
      "LLaMA-512: [1213    7    1    5    6    5    5    0    0    0]\n",
      "Alpaca: T1: [1048    7    4    6    4    0    1    1    0    0]\n",
      "Alpaca: T2: [1048    7    4    6    4    0    1    1    0    0]\n",
      "Alpaca: T3: [1048    7    4    6    4    0    1    1    0    0]\n",
      "Alpaca: T4: [1048    7    4    6    4    0    1    1    0    0]\n",
      "##############\n",
      "identity_hate\n",
      "....\n",
      "Real Stories: [1169    3    1    1    0    0    0    0    0    0]\n",
      "OPT-Line: [1071    0    0    0    0    0    0    0    0    0]\n",
      "OPT-256: [1161    0    6    0    0    0    0    0    0    0]\n",
      "OPT-512: [1232    5    5    0    0    0    0    0    0    0]\n",
      "LLaMA-Line: [1071    0    0    0    0    0    0    0    0    0]\n",
      "LLaMA-256: [1161    0    6    0    0    0    0    0    0    0]\n",
      "LLaMA-512: [1232    5    5    0    0    0    0    0    0    0]\n",
      "Alpaca: T1: [1071    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T2: [1071    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T3: [1071    0    0    0    0    0    0    0    0    0]\n",
      "Alpaca: T4: [1071    0    0    0    0    0    0    0    0    0]\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "measures = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for m in measures:\n",
    "    get_toxic_measure(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
